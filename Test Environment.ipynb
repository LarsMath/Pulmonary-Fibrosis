{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tqdm import tqdm\nimport seaborn as sns\nimport wandb\nfrom wandb.keras import WandbCallback\nimport keras\nfrom keras.models import Sequential\n\nfrom pfutils import (get_test_data, get_train_data, get_pseudo_test_data,\n                     build_model, get_cosine_annealing_lr_callback, get_fold_indices)\n\nWANDB = False\nTEST = False\nDATA_GENERATOR = False\n\n#If TEST is False use this to simulate tractable testcases. Should be 0 if TEST = True\nPSEUDO_TEST_PATIENTS = 26\nif TEST:\n    PSEUDO_TEST_PATIENTS = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# retrieve W&B key\n# from kaggle_secrets import UserSecretsClient\n# user_secrets = UserSecretsClient()\n# wandb_key = user_secrets.get_secret(\"wandb\")\n# assert wandb_key, \"Please create a key.txt or Kaggle Secret with your W&B API key\"\n\nwandb_key = \"ea9b3c785541508ffdd795f2a706df065df389e3\"\n\n!pip install -q --upgrade wandb\n!wandb login $wandb_key","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"if TEST:\n    test_data, submission = get_test_data(\"../input/osic-pulmonary-fibrosis-progression/test.csv\")\n    \ntrain, data, labels = get_train_data('../input/osic-pulmonary-fibrosis-progression/train.csv', PSEUDO_TEST_PATIENTS)\n\nif PSEUDO_TEST_PATIENTS > 0:\n    test_data, test_check = get_pseudo_test_data('../input/osic-pulmonary-fibrosis-progression/train.csv', PSEUDO_TEST_PATIENTS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## !!!! https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n\n# Dit is voor data generation on the fly voor bijv gaussian noise","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Settings And network"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of folds. A number between 1 and 176-PSEUDO_TEST_PATIENTS\nFOLDS = 3\n\n#Amount of features inputted in NN\nNUMBER_FEATURES = 9\n\n#State whether model should predict slope or single weeks\n#Predicting the slope is making the assumption that the decrease is linear\nPREDICT_SLOPE = False\n\n#Gaussian Noise\nUSE_GAUSSIAN_ON_FVC = False \nVALUE_GAUSSIAN_NOISE_ON_FVC = 70 # Only needed when Gaussian noise = True\n\n#Activation function to use\nACTIVATION_FUNCTION = 'relu'\n\n#Train length\nEPOCHS = 1000\nSTEPS_PER_EPOCH = 10\n\n#Learning rate\nMAX_LEARNING_RATE = 1e-4\nCOSINE_CYCLES = 10\n\nMODEL_NAME = \"10000 EPOCHS - 10 Cycles on FVC + datagenerator\"\n\nconfig = dict(NUMBER_FEATURES = NUMBER_FEATURES,\n              ACTIVATION_FUNCTION = ACTIVATION_FUNCTION,\n              EPOCHS = EPOCHS, STEPS_PER_EPOCH = STEPS_PER_EPOCH, MAX_LEARNING_RATE = MAX_LEARNING_RATE,\n              COSINE_CYCLES = COSINE_CYCLES, MODEL_NAME=MODEL_NAME, USE_GAUSSIAN_ON_FVC=USE_GAUSSIAN_ON_FVC,\n              VALUE_GAUSSIAN_NOISE_ON_FVC=VALUE_GAUSSIAN_NOISE_ON_FVC, PREDICT_SLOPE = PREDICT_SLOPE)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"model = build_model(config)\n#tf.keras.utils.plot_model(model)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Folds and Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"fold_pos = get_fold_indices(FOLDS, train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_cb = get_cosine_annealing_lr_callback(lr_max=config[\"MAX_LEARNING_RATE\"], \n                                            n_epochs=config[\"EPOCHS\"], \n                                            n_cycles=config[\"COSINE_CYCLES\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    def __init__(self, list_IDs, config, number_of_labels = 3,\n                 batch_size = 128, shuffle = True):\n        self.number_features = int(config[\"NUMBER_FEATURES\"])\n        self.use_gaussian = config[\"USE_GAUSSIAN_ON_FVC\"]\n        self.gauss_std = config[\"VALUE_GAUSSIAN_NOISE_ON_FVC\"]\n        self.list_IDs = list_IDs\n        self.batch_size = batch_size\n        self.labels = labels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n        self.label_size = number_of_labels\n    \n    def __len__(self):\n        return int(np.floor(len(self.list_IDs)/self.batch_size))\n    \n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, self.number_features))\n        y = np.empty((self.batch_size, self.label_size), dtype=int)\n        \n        data = np.load(\"./train_data.npy\", allow_pickle = True)\n        lab = np.load(\"./train_labels.npy\", allow_pickle = True)\n        \n        gauss = np.asarray(0)\n        \n        if self.use_gaussian:\n            gauss = np.random.normal(0, self.gauss_std, size = self.batch_size)\n        \n        for i, ID in enumerate(list_IDs_temp):\n            X[i,] = np.asarray(data[ID], dtype = \"float32\")\n            y[i,] = np.asarray(lab[ID], dtype = \"float32\")\n        \n        X[:,1] += gauss.astype(\"float32\")\n        y = np.asarray(y,dtype = \"float32\")\n        y[:,2] += gauss.astype(\"float32\")\n        \n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DATA_GENERATOR:\n    train_data = train[[\"Weeks\", \"FVC\", \"Percent\", \"Age\", \"Sex\", \n                                 \"Currently smokes\", \"Ex-smoker\", \"Never smoked\", \"Weekdiff_target\"]]\n    train_labels = labels\n    np.save(\"train_data.npy\", train_data.to_numpy())\n    np.save(\"train_labels.npy\", train_labels.to_numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\n\nfor fold in range(FOLDS):\n    \n    if DATA_GENERATOR:\n        train_ID = list(range(fold_pos[0],fold_pos[fold])) + list(range(fold_pos[fold+1],len(train)))\n        val_ID = list(range(fold_pos[fold], fold_pos[fold+1]))\n        # Generators\n        training_generator = DataGenerator(train_ID, config)\n        validation_generator = DataGenerator(val_ID, config)\n    else:\n        x_train = data[\"input_features\"][:fold_pos[fold]].append(data[\"input_features\"][fold_pos[fold+1]:])\n        y_train = labels[:fold_pos[fold]].append(labels[fold_pos[fold+1]:])\n        x_val = data[\"input_features\"][fold_pos[fold]:fold_pos[fold+1]]\n        y_val = labels[fold_pos[fold]:fold_pos[fold+1]]\n    \n    model = build_model(config)\n    \n    sv = tf.keras.callbacks.ModelCheckpoint(\n    'fold-%i.h5'%fold, monitor='val_loss', verbose=0, save_best_only=True,\n    save_weights_only=True, mode='min', save_freq='epoch')\n    callbacks = [lr_cb,sv]\n\n    print(fold+1, \"of\", FOLDS)\n    if WANDB:\n        name = MODEL_NAME + '-F{}'.format(fold+1)\n        config.update({'fold': fold+1})\n        wandb.init(project=\"osic-fibrosis\", name=name, config=config)\n        wandb_cb = WandbCallback()\n        callbacks.append(wandb_cb)\n        \n    if DATA_GENERATOR:\n        history = model.fit(training_generator, validation_data = validation_generator, epochs = EPOCHS,\n                            steps_per_epoch = STEPS_PER_EPOCH, verbose = 0, callbacks = callbacks)\n    else:\n        history = model.fit(x_train, y_train, validation_data = (x_val,y_val), epochs = EPOCHS,\n                            steps_per_epoch = STEPS_PER_EPOCH, verbose = 0, callbacks = callbacks)\n\n    if TEST or PSEUDO_TEST_PATIENTS > 0:\n        model.load_weights('fold-%i.h5'%fold)\n        predictions.append(model.predict(test_data, batch_size = 256))\n    \n    if WANDB:\n        # finalize run\n        wandb.join()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if TEST:\n    if PREDICT_SLOPE:\n        predictions = np.mean(predictions,axis = 0)\n        for i in range(1,len(test_data)+1):\n            submission.loc[i,\"FVC\"] = test_data.loc[i-1,\"FVC\"] + predictions[i-1,0]*test_data.loc[i-1,\"Weekdiff_target\"]\n            submission.loc[i, \"Confidence\"] = abs(predictions[i-1,1]*test_data.loc[i-1,\"Weekdiff_target\"])\n    else:\n        predictions = np.abs(predictions)\n        predictions[:,:,1] = np.power(predictions[:,:,1],2)\n        predictions = np.mean(predictions, axis = 0)\n        predictions[:,1] = np.power(predictions[:,1],0.5)\n        for i in range(1,len(test_data)+1):\n            submission.loc[i,\"FVC\"] = predictions[i-1,0]\n            submission.loc[i, \"Confidence\"] = predictions[i-1,1]\n    submission.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if PSEUDO_TEST_PATIENTS > 0:\n    predictions = np.abs(predictions)\n    predictions[:,:,1] = np.power(predictions[:,:,1],2)\n    predictions = np.mean(predictions, axis = 0)\n    predictions[:,1] = np.power(predictions[:,1],0.5)\n    FVC_true = test_check[\"TargetFVC\"].values\n    FVC_pred = predictions[:,0]\n    sigma = predictions[:,1]\n        \n    sigma_clip = np.maximum(np.abs(sigma), 70)\n    delta = np.abs(FVC_true - FVC_pred)\n    delta = np.minimum(delta, 1000)\n        \n    sq2 = np.sqrt(2)\n    loss = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip * sq2)\n    \n    print(np.mean(loss))\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}