{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "from pfutils import (get_test_data, get_train_data, get_pseudo_test_data, get_exponential_decay_lr_callback,\n",
    "                     build_model, get_cosine_annealing_lr_callback, get_fold_indices, DataGenerator)\n",
    "\n",
    "WANDB = True\n",
    "SUBMIT = False\n",
    "DATA_GENERATOR = True\n",
    "TRAIN_ON_BACKWARD_WEEKS = False\n",
    "\n",
    "#If TEST is False use this to simulate tractable testcases. Should be 0 if SUBMIT = True\n",
    "PSEUDO_TEST_PATIENTS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SUBMIT:\n",
    "    PSEUDO_TEST_PATIENTS = 0\n",
    "    WANDB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n",
      "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "if WANDB:    \n",
    "    # retrieve W&B key\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    wandb_key = user_secrets.get_secret(\"wandb_key\")\n",
    "    assert wandb_key, \"Please create a key.txt or Kaggle Secret with your W&B API key\"\n",
    "\n",
    "    #wandb_key = \"24020b558f39257d30a084a55cb438922c321495\"\n",
    "\n",
    "    !pip install wandb -qqq\n",
    "    !wandb login $wandb_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings And network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of folds. A number between 1 and 176-PSEUDO_TEST_PATIENTS. 176 = 2^4 * 11\n",
    "FOLDS = 5\n",
    "\n",
    "#Batch size\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "#Amount of features inputted in NN\n",
    "NUMBER_FEATURES = 9\n",
    "\n",
    "#Hidden layers\n",
    "HIDDEN_LAYERS = [64,64]\n",
    "\n",
    "#State whether model should predict slope or single weeks\n",
    "#Predicting the slope is making the assumption that the decrease is linear\n",
    "PREDICT_SLOPE = False\n",
    "\n",
    "#Gaussian Noise (the reported std error for FVC measurement devices is 70)\n",
    "#All values range approximately from 0 to 1 except FVC which is between 0 and 6688\n",
    "#0.01 change on Weeks corresponds to 1 week. Week_diff is changed accordingly\n",
    "#NOISE_SDS : [Weeks, FVC, Percent, Age, Sex, CurrentlySmokes, Ex-smoker, Never Smoked]\n",
    "NOISE_SDS = [0, 140, 0] + 5*[0.3]\n",
    "#GAUSSIAN_NOISE_CORRELATED is a boolean indicating if the gaussians added to X and y are perfectly correlated or independent\n",
    "GAUSSIAN_NOISE_FVC_CORRELATED = True\n",
    "ADD_NOISE_FVC_TO_PERCENT = True\n",
    "                           \n",
    "#Activation function to use ('swish', 'leakyrelu' or 'relu')\n",
    "ACTIVATION_FUNCTION = 'swish'\n",
    "\n",
    "#Experimenting with loss\n",
    "LOSS_MODIFICATION = 1 #(sqrt2 * delta / 70) * LOSS_MODIFICATION is added to the loss function (a value of 1 gives roughly equal weight to delta and sigma)\n",
    "OPTIMAL_SIGMA_LOSS = False\n",
    "\n",
    "#Dropout rate\n",
    "DROP_OUT_RATE = 0\n",
    "DROP_OUT_LAYERS = [] # [0,1,2] voor dropout in de eerste 3 lagen\n",
    "\n",
    "#Train length\n",
    "EPOCHS = 250\n",
    "\n",
    "#L2-Regularization\n",
    "L2_REGULARIZATION = False\n",
    "REGULARIZATION_CONSTANT = 0.0001\n",
    "\n",
    "#Input and/or output normalization\n",
    "INPUT_NORMALIZATION = True\n",
    "OUTPUT_NORMALIZATION = True\n",
    "\n",
    "#Learning rate\n",
    "LEARNING_RATE_SCHEDULER = 'exp' #'exp', 'cos' or None\n",
    "MAX_LEARNING_RATE = 0.001\n",
    "COSINE_CYCLES = 5\n",
    "EPOCHS_PER_OOM_DECAY = 250 #OoM : Order of Magnitude\n",
    "\n",
    "MODEL_NAME = \"Baseline\" \n",
    "\n",
    "config = dict(NUMBER_FEATURES = NUMBER_FEATURES, L2_REGULARIZATION = L2_REGULARIZATION, INPUT_NORMALIZATION = INPUT_NORMALIZATION,\n",
    "              ACTIVATION_FUNCTION = ACTIVATION_FUNCTION, DROP_OUT_RATE = DROP_OUT_RATE, OUTPUT_NORMALIZATION = OUTPUT_NORMALIZATION,\n",
    "              EPOCHS = EPOCHS, MAX_LEARNING_RATE = MAX_LEARNING_RATE, LOSS_MODIFICATION = LOSS_MODIFICATION, NOISE_SDS = NOISE_SDS, OPTIMAL_SIGMA_LOSS = OPTIMAL_SIGMA_LOSS,\n",
    "              COSINE_CYCLES = COSINE_CYCLES, MODEL_NAME=MODEL_NAME, LEARNING_RATE_SCHEDULER = LEARNING_RATE_SCHEDULER, PREDICT_SLOPE = PREDICT_SLOPE,\n",
    "              HIDDEN_LAYERS = HIDDEN_LAYERS, REGULARIZATION_CONSTANT = REGULARIZATION_CONSTANT, EPOCHS_PER_OOM_DECAY = EPOCHS_PER_OOM_DECAY,\n",
    "              DROP_OUT_LAYERS = DROP_OUT_LAYERS, BATCH_SIZE = BATCH_SIZE, GAUSSIAN_NOISE_FVC_CORRELATED = GAUSSIAN_NOISE_FVC_CORRELATED,\n",
    "              ADD_NOISE_FVC_TO_PERCENT = ADD_NOISE_FVC_TO_PERCENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SUBMIT:\n",
    "    test_data, submission = get_test_data(\"../input/osic-pulmonary-fibrosis-progression/test.csv\", INPUT_NORMALIZATION)\n",
    "    \n",
    "train, data, labels = get_train_data('../input/osic-pulmonary-fibrosis-progression/train.csv', PSEUDO_TEST_PATIENTS, INPUT_NORMALIZATION, TRAIN_ON_BACKWARD_WEEKS)\n",
    "\n",
    "if PSEUDO_TEST_PATIENTS > 0:\n",
    "    test_data, test_check = get_pseudo_test_data('../input/osic-pulmonary-fibrosis-progression/train.csv', PSEUDO_TEST_PATIENTS, INPUT_NORMALIZATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_179\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_features (InputLayer)     [(None, 9)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_356 (Dense)               (None, 64)           640         input_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_357 (Dense)               (None, 64)           4160        dense_356[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_358 (Dense)               (None, 64)           4160        dense_357[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FVC_output (Dense)              (None, 1)            65          dense_358[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigma_output (Dense)            (None, 1)            65          dense_358[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_356 (TensorFlow [(None, 1)]          0           FVC_output[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_357 (TensorFlow [(None, 1)]          0           sigma_output[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_358 (TensorFlow [(None, 1)]          0           tf_op_layer_Mul_356[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_359 (TensorFlow [(None, 1)]          0           tf_op_layer_Mul_357[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "slope_FVC (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "slope_Weekdiff (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 2)            0           tf_op_layer_Mul_358[0][0]        \n",
      "                                                                 tf_op_layer_Mul_359[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 9,090\n",
      "Trainable params: 9,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(config)\n",
    "#tf.keras.utils.plot_model(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folds and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1225, 2450, 3695, 4847, 6072]\n"
     ]
    }
   ],
   "source": [
    "fold_pos = get_fold_indices(FOLDS, train)\n",
    "print(fold_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_GENERATOR:\n",
    "    train_data = train[[\"Weeks\", \"FVC\", \"Percent\", \"Age\", \"Sex\", \n",
    "                                 \"Currently smokes\", \"Ex-smoker\", \"Never smoked\", \"Weekdiff_target\"]]\n",
    "    train_labels = labels\n",
    "    np.save(\"train_data.npy\", train_data.to_numpy())\n",
    "    np.save(\"train_labels.npy\", train_labels.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/larsranmath/pulfib\" target=\"_blank\">https://app.wandb.ai/larsranmath/pulfib</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/larsranmath/pulfib/runs/ixs0j1hk\" target=\"_blank\">https://app.wandb.ai/larsranmath/pulfib/runs/ixs0j1hk</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 of 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/larsranmath/pulfib\" target=\"_blank\">https://app.wandb.ai/larsranmath/pulfib</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/larsranmath/pulfib/runs/m21mtvkm\" target=\"_blank\">https://app.wandb.ai/larsranmath/pulfib/runs/m21mtvkm</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 of 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/larsranmath/pulfib\" target=\"_blank\">https://app.wandb.ai/larsranmath/pulfib</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/larsranmath/pulfib/runs/p2q7geqz\" target=\"_blank\">https://app.wandb.ai/larsranmath/pulfib/runs/p2q7geqz</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for fold in range(FOLDS):\n",
    "    if DATA_GENERATOR:\n",
    "        train_ID = list(range(fold_pos[0],fold_pos[fold])) + list(range(fold_pos[fold+1],len(train)))\n",
    "        val_ID = list(range(fold_pos[fold], fold_pos[fold+1]))\n",
    "        #train_ID = list(range(fold_pos[0],fold_pos[fold]))\n",
    "        #val_ID = list(range(fold_pos[0],fold_pos[fold]))\n",
    "        # Generators\n",
    "        training_generator = DataGenerator(train_ID, config)\n",
    "        validation_generator = DataGenerator(val_ID, config, validation = True)\n",
    "    else:\n",
    "        x_train = data[\"input_features\"][:fold_pos[fold]].append(data[\"input_features\"][fold_pos[fold+1]:])\n",
    "        y_train = labels[:fold_pos[fold]].append(labels[fold_pos[fold+1]:])\n",
    "        x_val = data[\"input_features\"][fold_pos[fold]:fold_pos[fold+1]]\n",
    "        y_val = labels[fold_pos[fold]:fold_pos[fold+1]]\n",
    "    \n",
    "    model = build_model(config)\n",
    "    \n",
    "    sv = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'fold-%i.h5'%fold, monitor='val_loss', verbose=0, save_best_only=True,\n",
    "    save_weights_only=True, mode='min', save_freq='epoch')\n",
    "    callbacks = [sv]\n",
    "    if LEARNING_RATE_SCHEDULER == 'exp':\n",
    "        callbacks.append(get_exponential_decay_lr_callback(config))\n",
    "    if LEARNING_RATE_SCHEDULER == 'cos':\n",
    "        callbacks.append(get_cosine_annealing_lr_callback(config))\n",
    "\n",
    "    print(fold+1, \"of\", FOLDS)\n",
    "    if WANDB:\n",
    "        name = MODEL_NAME + '-F{}'.format(fold+1)\n",
    "        config.update({'fold': fold+1})\n",
    "        wandb.init(project=\"pulfib\", name = name, config=config)\n",
    "        wandb_cb = WandbCallback()\n",
    "        callbacks.append(wandb_cb)\n",
    "        \n",
    "    if DATA_GENERATOR:\n",
    "        history = model.fit(training_generator, validation_data = validation_generator, epochs = EPOCHS,\n",
    "                            verbose = 0, callbacks = callbacks)\n",
    "    else:\n",
    "        history = model.fit(x_train, y_train, validation_data = (x_val,y_val), epochs = EPOCHS, verbose = 0, callbacks = callbacks)\n",
    "\n",
    "    if SUBMIT or PSEUDO_TEST_PATIENTS > 0:\n",
    "        model.load_weights('fold-%i.h5'%fold)\n",
    "        predictions.append(model.predict(test_data, batch_size = 256))\n",
    "    \n",
    "    if WANDB:\n",
    "        # finalize run\n",
    "        wandb.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SUBMIT:\n",
    "    if PREDICT_SLOPE:\n",
    "        predictions = np.mean(predictions,axis = 0)\n",
    "        for i in range(1,len(test_data)+1):\n",
    "            submission.loc[i,\"FVC\"] = test_data.loc[i-1,\"FVC\"] + predictions[i-1,0]*test_data.loc[i-1,\"Weekdiff_target\"]\n",
    "            submission.loc[i, \"Confidence\"] = abs(predictions[i-1,1]*test_data.loc[i-1,\"Weekdiff_target\"])\n",
    "    else:\n",
    "        predictions = np.abs(predictions)\n",
    "        predictions[:,:,1] = np.power(predictions[:,:,1],2)\n",
    "        predictions = np.mean(predictions, axis = 0)\n",
    "        predictions[:,1] = np.power(predictions[:,1],0.5)\n",
    "        for i in range(1,len(test_data)+1):\n",
    "            submission.loc[i,\"FVC\"] = predictions[i-1,0]\n",
    "            submission.loc[i, \"Confidence\"] = predictions[i-1,1]\n",
    "    submission.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gmean\n",
    "if PSEUDO_TEST_PATIENTS > 0:\n",
    "    result = []\n",
    "    for i in range(-20,20):\n",
    "        postprocess = np.abs(predictions)\n",
    "        if i == 0:\n",
    "            postprocess[:,:,1] = gmean(postprocess[:,:,1], axis = 0)\n",
    "            postprocess = np.mean(postprocess, axis = 0)\n",
    "        else:\n",
    "            postprocess[:,:,1] = np.power(postprocess[:,:,1],i)\n",
    "            postprocess = np.mean(postprocess, axis = 0)\n",
    "            postprocess[:,1] = np.power(postprocess[:,1],1/i)\n",
    "        FVC_true = test_check[\"TargetFVC\"].values\n",
    "        FVC_pred = postprocess[:,0]\n",
    "        sigma = postprocess[:,1]\n",
    "\n",
    "        sigma_clip = np.maximum(np.abs(sigma), 70)\n",
    "        delta = np.abs(FVC_true - FVC_pred)\n",
    "        delta = np.minimum(delta, 1000)\n",
    "\n",
    "        sq2 = np.sqrt(2)\n",
    "        loss = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip * sq2)\n",
    "        result.append(np.mean(loss))\n",
    "    plt.plot(np.arange(-20,20),result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
