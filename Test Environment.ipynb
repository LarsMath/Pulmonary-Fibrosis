{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tqdm import tqdm\nimport seaborn as sns\nimport wandb\nfrom wandb.keras import WandbCallback\nimport keras\nfrom keras.models import Sequential\n\nfrom pfutils import (get_test_data, get_train_data, get_pseudo_test_data,\n                     build_model, get_cosine_annealing_lr_callback, get_fold_indices)\n\nWANDB = True\nTEST = True\nDATA_GENERATOR = True\nTRAIN_ON_BACKWARD_WEEKS = False\n\n#If TEST is False use this to simulate tractable testcases. Should be 0 if TEST = True\nPSEUDO_TEST_PATIENTS = 0","execution_count":101,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if TEST:\n    PSEUDO_TEST_PATIENTS = 0","execution_count":102,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# retrieve W&B key\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_key = user_secrets.get_secret(\"wandb_key\")\nassert wandb_key, \"Please create a key.txt or Kaggle Secret with your W&B API key\"\n\n#wandb_key = \"24020b558f39257d30a084a55cb438922c321495\"\n\n!pip install -q --upgrade wandb\n!wandb login $wandb_key","execution_count":103,"outputs":[{"output_type":"stream","text":"\u001b[33mWARNING: You are using pip version 20.2.1; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Preparing the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"## !!!! https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n\n# Dit is voor data generation on the fly voor bijv gaussian noise","execution_count":104,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Settings And network"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of folds. A number between 1 and 176-PSEUDO_TEST_PATIENTS\nFOLDS = 10\n\n#Batch size\nBATCH_SIZE = 128\n\n#Amount of features inputted in NN\nNUMBER_FEATURES = 9\n\n#Hidden layers\nHIDDEN_LAYERS = [64,64]\n\n#State whether model should predict slope or single weeks\n#Predicting the slope is making the assumption that the decrease is linear\nPREDICT_SLOPE = False\n\n#Gaussian Noise (the reported std error for measurement devices is 70)\n#GAUSS_ALLIGNED is a boolean indicating if the gaussians added to X and y are perfectly correlated or independent\nUSE_GAUSSIAN_ON_FVC = True \nVALUE_GAUSSIAN_NOISE_ON_FVC = 70 # Only needed when Gaussian noise = True\nGAUSSIAN_NOISE_CORRELATED = False\n                                     \n#Activation function to use ('swish' or 'relu')\nACTIVATION_FUNCTION = 'swish'\n\n#Dropout rate\nDROP_OUT_RATE = 0\nDROP_OUT_LAYERS = [] # [0,1,2] voor dropout in de eerste 3 lagen\n\n#Train length\nEPOCHS = 100\nSTEPS_PER_EPOCH = 100\n\n#L2-Regularization\nL2_REGULARIZATION = False\nREGULARIZATION_CONSTANT = 0.005\n\n#Input and/or output normalization\nINPUT_NORMALIZATION = True\nOUTPUT_NORMALIZATION = True\n\n#Learning rate\nMAX_LEARNING_RATE = 5e-4\nCOSINE_CYCLES = 10\n\nMODEL_NAME = \"Baseline\" \n\nconfig = dict(NUMBER_FEATURES = NUMBER_FEATURES, L2_REGULARIZATION = L2_REGULARIZATION, INPUT_NORMALIZATION =INPUT_NORMALIZATION,\n              ACTIVATION_FUNCTION = ACTIVATION_FUNCTION, DROP_OUT_RATE = DROP_OUT_RATE, OUTPUT_NORMALIZATION = OUTPUT_NORMALIZATION,\n              EPOCHS = EPOCHS, STEPS_PER_EPOCH = STEPS_PER_EPOCH, MAX_LEARNING_RATE = MAX_LEARNING_RATE,\n              COSINE_CYCLES = COSINE_CYCLES, MODEL_NAME=MODEL_NAME, USE_GAUSSIAN_ON_FVC=USE_GAUSSIAN_ON_FVC,\n              VALUE_GAUSSIAN_NOISE_ON_FVC=VALUE_GAUSSIAN_NOISE_ON_FVC, PREDICT_SLOPE = PREDICT_SLOPE,\n              HIDDEN_LAYERS = HIDDEN_LAYERS, REGULARIZATION_CONSTANT = REGULARIZATION_CONSTANT,\n              DROP_OUT_LAYERS = DROP_OUT_LAYERS, BATCH_SIZE = BATCH_SIZE, GAUSSIAN_NOISE_CORRELATED = GAUSSIAN_NOISE_CORRELATED )","execution_count":105,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if TEST:\n    test_data, submission = get_test_data(\"../input/osic-pulmonary-fibrosis-progression/test.csv\", INPUT_NORMALIZATION)\n    \ntrain, data, labels = get_train_data('../input/osic-pulmonary-fibrosis-progression/train.csv', PSEUDO_TEST_PATIENTS, INPUT_NORMALIZATION, TRAIN_ON_BACKWARD_WEEKS)\n\nif PSEUDO_TEST_PATIENTS > 0:\n    test_data, test_check = get_pseudo_test_data('../input/osic-pulmonary-fibrosis-progression/train.csv', PSEUDO_TEST_PATIENTS, INPUT_NORMALIZATION)","execution_count":107,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"model = build_model(config)\n#tf.keras.utils.plot_model(model)\nmodel.summary()","execution_count":108,"outputs":[{"output_type":"stream","text":"Model: \"functional_37\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_features (InputLayer)     [(None, 9)]          0                                            \n__________________________________________________________________________________________________\ndense_36 (Dense)                (None, 64)           640         input_features[0][0]             \n__________________________________________________________________________________________________\ndense_37 (Dense)                (None, 64)           4160        dense_36[0][0]                   \n__________________________________________________________________________________________________\nFVC_output (Dense)              (None, 1)            65          dense_37[0][0]                   \n__________________________________________________________________________________________________\nsigma_output (Dense)            (None, 1)            65          dense_37[0][0]                   \n__________________________________________________________________________________________________\ntf_op_layer_Mul_72 (TensorFlowO [(None, 1)]          0           FVC_output[0][0]                 \n__________________________________________________________________________________________________\ntf_op_layer_Mul_73 (TensorFlowO [(None, 1)]          0           sigma_output[0][0]               \n__________________________________________________________________________________________________\ntf_op_layer_Mul_74 (TensorFlowO [(None, 1)]          0           tf_op_layer_Mul_72[0][0]         \n__________________________________________________________________________________________________\ntf_op_layer_Mul_75 (TensorFlowO [(None, 1)]          0           tf_op_layer_Mul_73[0][0]         \n__________________________________________________________________________________________________\nslope_FVC (InputLayer)          [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nslope_Weekdiff (InputLayer)     [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nconcatenate_18 (Concatenate)    (None, 2)            0           tf_op_layer_Mul_74[0][0]         \n                                                                 tf_op_layer_Mul_75[0][0]         \n==================================================================================================\nTotal params: 4,930\nTrainable params: 4,930\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Folds and Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"fold_pos = get_fold_indices(FOLDS, train)\nprint(fold_pos)","execution_count":109,"outputs":[{"output_type":"stream","text":"[0, 2009, 4067, 6072]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    def __init__(self, list_IDs, config, validation = False, number_of_labels = 3,\n                 batch_size = 128, shuffle = True):\n        self.number_features = int(config[\"NUMBER_FEATURES\"])\n        self.use_gaussian = config[\"USE_GAUSSIAN_ON_FVC\"]\n        self.gauss_std = config[\"VALUE_GAUSSIAN_NOISE_ON_FVC\"] and not validation\n        self.list_IDs = list_IDs\n        self.batch_size = config[\"BATCH_SIZE\"]\n        self.labels = labels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n        self.label_size = number_of_labels\n        self.normalized = config[\"INPUT_NORMALIZATION\"]\n        self.correlated = config[\"GAUSSIAN_NOISE_CORRELATED\"]\n    \n    def __len__(self):\n        return int(np.floor(len(self.list_IDs)/self.batch_size))\n    \n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, self.number_features))\n        y = np.empty((self.batch_size, self.label_size), dtype=int)\n        \n        data = np.load(\"./train_data.npy\", allow_pickle = True)\n        lab = np.load(\"./train_labels.npy\", allow_pickle = True)\n        \n        for i, ID in enumerate(list_IDs_temp):\n            X[i,] = np.asarray(data[ID], dtype = \"float32\")\n            y[i,] = np.asarray(lab[ID], dtype = \"float32\")\n        y = np.asarray(y,dtype = \"float32\")\n            \n        gauss_X = np.random.normal(0, self.gauss_std, size = self.batch_size)\n        \n        if self.correlated:\n            gauss_y = gauss_X\n        else:\n            gauss_y = np.random.normal(0, self.gauss_std, size = self.batch_size)\n        if self.normalized:\n            gauss_X = gauss_X/5000 \n            \n        X[:,1] += gauss_X.astype(\"float32\")\n        y[:,2] += gauss_X.astype(\"float32\")\n        y[:,0] += gauss_y.astype(\"float32\")\n        \n        return X, y","execution_count":110,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DATA_GENERATOR:\n    train_data = train[[\"Weeks\", \"FVC\", \"Percent\", \"Age\", \"Sex\", \n                                 \"Currently smokes\", \"Ex-smoker\", \"Never smoked\", \"Weekdiff_target\"]]\n    train_labels = labels\n    np.save(\"train_data.npy\", train_data.to_numpy())\n    np.save(\"train_labels.npy\", train_labels.to_numpy())","execution_count":111,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\n\nfor fold in range(FOLDS):\n    if DATA_GENERATOR:\n        train_ID = list(range(fold_pos[0],fold_pos[fold])) + list(range(fold_pos[fold+1],len(train)))\n        val_ID = list(range(fold_pos[fold], fold_pos[fold+1]))\n        # Generators\n        training_generator = DataGenerator(train_ID, config)\n        validation_generator = DataGenerator(val_ID, config, validation = True)\n    else:\n        x_train = data[\"input_features\"][:fold_pos[fold]].append(data[\"input_features\"][fold_pos[fold+1]:])\n        y_train = labels[:fold_pos[fold]].append(labels[fold_pos[fold+1]:])\n        x_val = data[\"input_features\"][fold_pos[fold]:fold_pos[fold+1]]\n        y_val = labels[fold_pos[fold]:fold_pos[fold+1]]\n    \n    model = build_model(config)\n    \n    sv = tf.keras.callbacks.ModelCheckpoint(\n    'fold-%i.h5'%fold, monitor='val_loss', verbose=0, save_best_only=True,\n    save_weights_only=True, mode='min', save_freq='epoch')\n    callbacks = [sv]\n\n    print(fold+1, \"of\", FOLDS)\n    if WANDB:\n        name = MODEL_NAME + '-F{}'.format(fold+1)\n        config.update({'fold': fold+1})\n        wandb.init(project=\"pulfib\", name=name, config=config)\n        wandb_cb = WandbCallback()\n        callbacks.append(wandb_cb)\n        \n    if DATA_GENERATOR:\n        history = model.fit(training_generator, validation_data = validation_generator, epochs = EPOCHS,\n                            verbose = 0, callbacks = callbacks)\n    else:\n        history = model.fit(x_train, y_train, validation_data = (x_val,y_val), epochs = EPOCHS,\n                            steps_per_epoch = STEPS_PER_EPOCH, verbose = 0, callbacks = callbacks)\n\n    if TEST or PSEUDO_TEST_PATIENTS > 0:\n        model.load_weights('fold-%i.h5'%fold)\n        predictions.append(model.predict(test_data, batch_size = 256))\n    \n    if WANDB:\n        # finalize run\n        wandb.join()","execution_count":112,"outputs":[{"output_type":"stream","text":"1 of 3\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/larsranmath/pulfib\" target=\"_blank\">https://app.wandb.ai/larsranmath/pulfib</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/larsranmath/pulfib/runs/3ridipji\" target=\"_blank\">https://app.wandb.ai/larsranmath/pulfib/runs/3ridipji</a><br/>\n            "},"metadata":{}},{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.9.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","name":"stderr"},{"output_type":"stream","text":"2 of 3\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/larsranmath/pulfib\" target=\"_blank\">https://app.wandb.ai/larsranmath/pulfib</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/larsranmath/pulfib/runs/15e4xvcu\" target=\"_blank\">https://app.wandb.ai/larsranmath/pulfib/runs/15e4xvcu</a><br/>\n            "},"metadata":{}},{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.9.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","name":"stderr"},{"output_type":"stream","text":"3 of 3\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/larsranmath/pulfib\" target=\"_blank\">https://app.wandb.ai/larsranmath/pulfib</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/larsranmath/pulfib/runs/3oyk751x\" target=\"_blank\">https://app.wandb.ai/larsranmath/pulfib/runs/3oyk751x</a><br/>\n            "},"metadata":{}},{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.9.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"if TEST:\n    if PREDICT_SLOPE:\n        predictions = np.mean(predictions,axis = 0)\n        for i in range(1,len(test_data)+1):\n            submission.loc[i,\"FVC\"] = test_data.loc[i-1,\"FVC\"] + predictions[i-1,0]*test_data.loc[i-1,\"Weekdiff_target\"]\n            submission.loc[i, \"Confidence\"] = abs(predictions[i-1,1]*test_data.loc[i-1,\"Weekdiff_target\"])\n    else:\n        predictions = np.abs(predictions)\n        predictions[:,:,1] = np.power(predictions[:,:,1],2)\n        predictions = np.mean(predictions, axis = 0)\n        predictions[:,1] = np.power(predictions[:,1],0.5)\n        for i in range(1,len(test_data)+1):\n            submission.loc[i,\"FVC\"] = predictions[i-1,0]\n            submission.loc[i, \"Confidence\"] = predictions[i-1,1]\n    submission.to_csv(\"submission.csv\", index = False)","execution_count":113,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"backup = predictions","execution_count":114,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom scipy.stats import gmean\nif PSEUDO_TEST_PATIENTS > 0:\n    result = []\n    for i in range(-20,20):\n        predictions = np.abs(backup)\n        if i == 0:\n            predictions[:,:,1] = gmean(predictions[:,:,1], axis = 0)\n            predictions = np.mean(predictions, axis = 0)\n        else:\n            predictions[:,:,1] = np.power(predictions[:,:,1],i)\n            predictions = np.mean(predictions, axis = 0)\n            predictions[:,1] = np.power(predictions[:,1],1/i)\n        FVC_true = test_check[\"TargetFVC\"].values\n        FVC_pred = predictions[:,0]\n        sigma = predictions[:,1]\n\n        sigma_clip = np.maximum(np.abs(sigma), 70)\n        delta = np.abs(FVC_true - FVC_pred)\n        delta = np.minimum(delta, 1000)\n\n        sq2 = np.sqrt(2)\n        loss = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip * sq2)\n        result.append(np.mean(loss))\n    plt.plot(np.arange(-20,20),result)\n","execution_count":115,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}