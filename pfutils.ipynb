{"cells":[{"metadata":{"_uuid":"f4777731-d3e4-4efb-8fdd-f1705cf8d7d9","_cell_guid":"eb2d3c9d-d8b9-47fa-991b-ac16c6b57c7d","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\n\n\ndef get_test_data(files):\n    test = pd.read_csv(files)\n    submission = pd.DataFrame(columns=['Patient_Week', 'FVC', 'Confidence'])\n\n    count = 0\n    #Submission File\n    for patient in test[\"Patient\"]:\n        for i in range(-12,133+1):\n            count += 1\n            submission.loc[count, \"Patient_Week\"] = patient + \"_\" + str(i)\n            submission.loc[count, \"FVC\"] = 0\n            submission.loc[count, \"Confidence\"] = 0\n\n    test_data = pd.DataFrame(columns = [\"Weeks\", \"FVC\", \"Percent\", \"Age\", \"Sex\", \n                                        \"Weekdiff_target\", 'SmokingStatus'])\n\n    count = 0\n    for patient in test[\"Patient\"]:\n        for i in range(-12,133+1):\n            count+=1\n            test_data.loc[count, \"Patient_Week\"] = patient + \"_\" + str(i)\n            test_data.loc[count, \"Weekdiff_target\"] = i - test[test[\"Patient\"] == patient][\"Weeks\"].values[0] \n            test_data.loc[count, \"Weeks\"] = test[test[\"Patient\"] == patient][\"Weeks\"].values[0]\n            test_data.loc[count, \"FVC\"] = test[test[\"Patient\"] == patient][\"FVC\"].values[0]\n            test_data.loc[count, \"Percent\"] = test[test[\"Patient\"] == patient][\"Percent\"].values[0]\n            test_data.loc[count, \"Sex\"] = test[test[\"Patient\"] == patient][\"Sex\"].values[0]\n            test_data.loc[count, 'SmokingStatus'] = test[test[\"Patient\"] == patient]['SmokingStatus'].values[0]\n            test_data.loc[count, 'Age'] = test[test[\"Patient\"] == patient]['Age'].values[0]\n\n    test_data[\"Sex\"] = (test_data['Sex']==\"Male\").astype(int)\n    test_data = pd.concat([test_data,pd.get_dummies(test_data['SmokingStatus'])],axis = 1).reset_index(drop = True)\n    test_data = test_data.drop([\"SmokingStatus\", \"Patient_Week\"],axis = 1)\n\n    Check = [\"Currently smokes\", \"Ex-smoker\", \"Never smoked\"]\n\n    for col in Check:\n        if col not in test_data.columns:\n            test_data[col] = 0\n\n    test_data = test_data[[\"Weeks\", \"FVC\", \"Percent\", \"Age\", \"Sex\", \"Currently smokes\",\n               \"Ex-smoker\", \"Never smoked\", \"Weekdiff_target\"]]\n    test_data = test_data.astype(\"Float32\")\n    \n    return test_data, submission\n\ndef get_train_data(files, pseudo_test_patients):\n    df = pd.read_csv(files)\n    patients = []\n    for patient in df.Patient.unique()[pseudo_test_patients:]:\n        weekcombinations = []\n        weeks = df.loc[df.Patient == patient]['Weeks']\n        for week1 in weeks:\n            dfnew = df.loc[(df.Patient == patient) & (df.Weeks != week1)]\n            dfnew = dfnew.assign(Weekdiff_target = week1)\n            dfnew = dfnew.assign(TargetFVC = df.loc[(df.Patient == patient)&(df.Weeks == week1)]['FVC'].values[0])\n            weekcombinations.append(dfnew)\n            patients.append(pd.concat(weekcombinations))\n\n    train = pd.DataFrame(pd.concat(patients))    \n    train[\"Sex\"] = (train['Sex']==\"Male\").astype(int)\n\n    train = pd.concat([train,pd.get_dummies(train['SmokingStatus'])],axis = 1).reset_index(drop = True)\n    for i in range(len(train)):\n        train.loc[i, \"Weekdiff_target\"] = train.loc[i, \"Weekdiff_target\"] - train.loc[i, \"Weeks\"]\n    \n    labels = pd.DataFrame(train[[\"TargetFVC\",\"Weekdiff_target\",\"FVC\"]])\n    labels = labels.astype(\"float32\")\n    \n    train = train[[\"Weeks\", \"FVC\", \"Percent\", \"Age\", \"Sex\", \"Currently smokes\",\n                   \"Ex-smoker\", \"Never smoked\", \"Weekdiff_target\", \"Patient\"]]\n\n    data = {\"input_features\": train[[\"Weeks\", \"FVC\", \"Percent\", \"Age\", \"Sex\", \n                                     \"Currently smokes\", \"Ex-smoker\", \"Never smoked\", \"Weekdiff_target\"]],\n            \"FVC_Start_Weeks_from_start\": train[\"Weekdiff_target\"]}\n    \n    return train, data, labels\n\ndef get_pseudo_test_data(files, pseudo_test_patients, random_seed = 42):\n    np.random.seed(random_seed)\n    \n    df = pd.read_csv(files)\n    patients = df.Patient.unique()[:pseudo_test_patients]\n\n    test_data = pd.DataFrame(columns = [\"Weeks\", \"FVC\", \"Percent\", \"Age\", \"Sex\", \n                                        \"Weekdiff_target\", 'SmokingStatus'])\n    test_check = pd.DataFrame(columns = [\"TargetFVC\",\"Weekdiff_target\",\"FVC\"])\n\n    count = 0\n    for patient in patients:\n        init_choice = int((len(df[df.Patient == patient])-3)*np.random.rand())\n        basecase = df[df.Patient == patient].iloc[init_choice]\n        for testcase in df[df.Patient == patient].iloc[-3:].iterrows():\n            count+=1\n            test_data.loc[count, \"Patient_Week\"] = patient + \"_\" + str(testcase[1][\"Weeks\"])\n            test_data.loc[count, \"Weekdiff_target\"] = testcase[1][\"Weeks\"] - basecase[\"Weeks\"]\n            test_data.loc[count, \"Weeks\"] = basecase[\"Weeks\"]\n            test_data.loc[count, \"FVC\"] = basecase[\"FVC\"]\n            test_data.loc[count, \"Percent\"] = basecase[\"Percent\"]\n            test_data.loc[count, \"Sex\"] = basecase[\"Sex\"]\n            test_data.loc[count, 'SmokingStatus'] = basecase['SmokingStatus']\n            test_data.loc[count, 'Age'] = basecase['Age']\n            test_check.loc[count, \"TargetFVC\"] = testcase[1][\"FVC\"]\n            test_check.loc[count, \"Weekdiff_target\"] = testcase[1][\"Weeks\"] - basecase[\"Weeks\"]\n            test_check.loc[count, \"FVC\"] = basecase[\"FVC\"]\n\n    test_data[\"Sex\"] = (test_data['Sex']==\"Male\").astype(int)\n    test_data = pd.concat([test_data,pd.get_dummies(test_data['SmokingStatus'])],axis = 1).reset_index(drop = True)\n    test_data = test_data.drop([\"SmokingStatus\", \"Patient_Week\"],axis = 1)\n    \n    Check = [\"Currently smokes\", \"Ex-smoker\", \"Never smoked\"]\n\n    for col in Check:\n        if col not in test_data.columns:\n            test_data[col] = 0\n    test_data = test_data[[\"Weeks\", \"FVC\", \"Percent\", \"Age\", \"Sex\", \"Currently smokes\",\n                           \"Ex-smoker\", \"Never smoked\", \"Weekdiff_target\"]]\n    \n    test_data = test_data.astype(\"Float32\")\n    test_check = test_check.astype(\"Float32\")\n    \n    return test_data, test_check\n\ndef build_model(config):\n    \n    size = config[\"NUMBER_FEATURES\"]\n    actfunc = config[\"ACTIVATION_FUNCTION\"]\n    predict_slope = config[\"PREDICT_SLOPE\"]\n    \n    if(actfunc == 'swish'):\n        actfunc = tf.keras.activations.swish\n\n    inp = tf.keras.layers.Input(shape=(1,size), name = \"input_features\")\n    \n    inp2 = tf.keras.layers.Input(shape = (1,1), name = \"FVC_Start_Weeks_from_start\")\n    \n    inputs = [inp]\n    outputs = []\n    \n    x = tf.keras.layers.Dense(100, activation=actfunc)(inp)\n    x = tf.keras.layers.Dense(75, activation=actfunc)(x)\n    x = tf.keras.layers.Dense(50, activation=actfunc)(x)\n    x = tf.keras.layers.Dense(25, activation=actfunc)(x)\n    x = tf.keras.layers.Dense(15, activation=actfunc)(x)\n    x = tf.keras.layers.Dense(10, activation=actfunc)(x)\n\n    \n    # output : [slope/FVC_pred, s/sigma, FVC_start, weeks_from_start]\n    outputs += [tf.keras.layers.Dense(2, name = \"Output_a_s\")(x)]\n\n    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n    \n    def Laplace_log_likelihood(y_true, y_pred):\n        # y_pred : [slope/FVC_pred, s/sigma, FVC_start, weeks_from_start]\n        y_true = tf.dtypes.cast(y_true, tf.float32)\n        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n        FVC_true = y_true[:,0]\n        \n        if(predict_slope):\n            slope = y_pred[:,0]\n            s = y_pred[:,1]\n\n            weeks_from_start = y_true[:,1]\n            FVC_start = y_true[:,2]\n            \n            sigma = s * weeks_from_start\n            # Kan probleem worden by ReLu omdat slope negatief wordt door minimalisering Loss\n            FVC_pred = weeks_from_start * slope + FVC_start\n        else:\n            FVC_pred = tf.abs(y_pred[:,0])\n            sigma = tf.abs(y_pred[:,1])\n        \n        ## ** Hier kan een fout komen doordat de afgeleide moeilijker te berekenen is\n        sigma_clip = tf.maximum(tf.abs(sigma), 70)\n        delta = tf.abs(FVC_true - FVC_pred)\n        ## **\n        \n        sq2 = tf.sqrt(tf.dtypes.cast(2, dtype=tf.float32))\n        loss = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip * sq2)\n        return K.mean(loss)\n    \n    def Laplace_metric(y_true, y_pred):\n        # y_pred : [slope/FVC_pred, s/sigma, FVC_start, weeks_from_start]\n        y_true = tf.dtypes.cast(y_true, tf.float32)\n        y_pred = tf.dtypes.cast(y_pred, tf.float32)\n        FVC_true = y_true[:,0]\n        \n        if(predict_slope):\n            slope = y_pred[:,0]\n            s = y_pred[:,1]\n\n            weeks_from_start = y_true[:,1]\n            FVC_start = y_true[:,2]\n            \n            sigma = s * weeks_from_start\n            # Kan probleem worden by ReLu omdat slope negatief wordt door minimalisering Loss\n            FVC_pred = weeks_from_start * slope + FVC_start\n        else:\n            FVC_pred = tf.abs(y_pred[:,0])\n            sigma = tf.abs(y_pred[:,1])\n        \n        ## ** Hier kan een fout komen doordat de afgeleide moeilijker te berekenen is\n        sigma_clip = tf.maximum(tf.abs(sigma), 70)\n        delta = tf.abs(FVC_true - FVC_pred)\n        delta = tf.minimum(delta, 1000)\n        ## **\n        \n        sq2 = tf.sqrt(tf.dtypes.cast(2, dtype=tf.float32))\n        loss = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip * sq2)\n        return K.mean(loss)\n    \n    \n    opt = tf.keras.optimizers.Adam()\n    model.compile(optimizer=opt, loss=Laplace_log_likelihood, metrics = [Laplace_metric])\n\n    return model\n\ndef get_cosine_annealing_lr_callback(lr_max=1e-4, n_epochs= 10000, n_cycles= 10):\n    epochs_per_cycle = np.floor(n_epochs / n_cycles)\n\n    def lrfn(epoch):\n        cos_inner = (np.pi * (epoch % epochs_per_cycle)) / epochs_per_cycle\n        return lr_max / 2 * (np.cos(cos_inner) + 1)\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    \n    return lr_callback\n\ndef get_fold_indices(folds, train):\n    \n    fold_pos = [0]\n    count = 0\n    for i in np.unique(train[\"Patient\"]):\n        count += 1\n        if count >= (len(fold_pos)*len(np.unique(train.Patient))/folds):\n            fold_pos.append(np.max(np.where(train[\"Patient\"] == i))+1)\n            \n    return fold_pos","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}